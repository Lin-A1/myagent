# MyAgent åç«¯ API æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» MyAgent åç«¯æœåŠ¡çš„ REST API æ¥å£ã€‚

## ğŸ“‹ ç›®å½•

- [æœåŠ¡å™¨å¯åŠ¨](#æœåŠ¡å™¨å¯åŠ¨)
- [API æ¦‚è§ˆ](#api-æ¦‚è§ˆ)
- [LLM API](#llm-api)
  - [èŠå¤©æ¥å£](#èŠå¤©æ¥å£)
  - [ä¸Šä¸‹æ–‡ç®¡ç†](#ä¸Šä¸‹æ–‡ç®¡ç†)
  - [å¥åº·æ£€æŸ¥](#å¥åº·æ£€æŸ¥)
  - [æœåŠ¡ä¿¡æ¯](#æœåŠ¡ä¿¡æ¯)
- [OCR API](#ocr-api)
  - [æ–‡å­—è¯†åˆ«](#æ–‡å­—è¯†åˆ«)
- [æ•°æ®æ¨¡å‹](#æ•°æ®æ¨¡å‹)
- [é”™è¯¯å¤„ç†](#é”™è¯¯å¤„ç†)
- [è®¤è¯é…ç½®](#è®¤è¯é…ç½®)
- [å®¢æˆ·ç«¯ç¤ºä¾‹](#å®¢æˆ·ç«¯ç¤ºä¾‹)

## ğŸš€ æœåŠ¡å™¨å¯åŠ¨

### å¯åŠ¨å¼€å‘æœåŠ¡å™¨

```bash
# æ–¹å¼1ï¼šä½¿ç”¨ run_server.py
python src/server/run_server.py

# æ–¹å¼2ï¼šä½¿ç”¨ uvicorn
uvicorn src.server.main:app --host 0.0.0.0 --port 8000 --reload
```

### è®¿é—® API æ–‡æ¡£

å¯åŠ¨æœåŠ¡å™¨åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹åœ°å€è®¿é—®ï¼š

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI JSON**: http://localhost:8000/openapi.json

## ğŸ“Š API æ¦‚è§ˆ

### åŸºç¡€ä¿¡æ¯

- **åŸºç¡€URL**: `http://localhost:8000`
- **å†…å®¹ç±»å‹**: `application/json`
- **å­—ç¬¦ç¼–ç **: `UTF-8`

### ç«¯ç‚¹åˆ—è¡¨

| æ–¹æ³• | ç«¯ç‚¹ | æè¿° |
|------|------|------|
| POST | `/llm/chat` | LLM èŠå¤©å¯¹è¯ |
| GET | `/llm/context/{session_id}` | è·å–å¯¹è¯ä¸Šä¸‹æ–‡ |
| POST | `/llm/context/{session_id}` | è®¾ç½®å¯¹è¯ä¸Šä¸‹æ–‡ |
| DELETE | `/llm/context/{session_id}` | æ¸…ç©ºå¯¹è¯ä¸Šä¸‹æ–‡ |
| DELETE | `/llm/context/{session_id}/last` | åˆ é™¤æœ€åä¸€è½®å¯¹è¯ |
| GET | `/llm/health` | LLM æœåŠ¡å¥åº·æ£€æŸ¥ |
| GET | `/llm/info` | LLM æœåŠ¡ä¿¡æ¯ |
| POST | `/ocr/recognize` | OCR æ–‡å­—è¯†åˆ« |
| GET | `/health` | æ•´ä½“æœåŠ¡å¥åº·æ£€æŸ¥ |

## ğŸ¤– LLM API

### èŠå¤©æ¥å£

**ç«¯ç‚¹**: `POST /llm/chat`

å‘é€æ¶ˆæ¯ç»™ LLM å¹¶è·å–å›å¤ã€‚

#### è¯·æ±‚ä½“

```json
{
  "message": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±",
  "config": {
    "api_key": "your-api-key",
    "model": "gpt-3.5-turbo",
    "base_url": "https://api.openai.com/v1",
    "temperature": 0.7,
    "max_tokens": 1000
  },
  "session_id": "user123",
  "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹",
  "keep_context": true
}
```

#### å“åº”

```json
{
  "response": "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡...",
  "session_id": "user123",
  "model": "gpt-3.5-turbo",
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 50,
    "total_tokens": 70
  }
}
```

#### cURL ç¤ºä¾‹

```bash
curl -X POST "http://localhost:8000/llm/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ä½ å¥½",
    "config": {
      "api_key": "your-api-key",
      "model": "gpt-3.5-turbo"
    },
    "session_id": "test_session"
  }'
```

### ä¸Šä¸‹æ–‡ç®¡ç†

#### è·å–ä¸Šä¸‹æ–‡

**ç«¯ç‚¹**: `GET /llm/context/{session_id}`

```bash
curl "http://localhost:8000/llm/context/user123"
```

**å“åº”**:
```json
{
  "session_id": "user123",
  "messages": [
    {"role": "user", "content": "ä½ å¥½"},
    {"role": "assistant", "content": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"}
  ],
  "message_count": 2
}
```

#### è®¾ç½®ä¸Šä¸‹æ–‡

**ç«¯ç‚¹**: `POST /llm/context/{session_id}`

```bash
curl -X POST "http://localhost:8000/llm/context/user123" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹"},
      {"role": "user", "content": "è¯·ç¿»è¯‘ï¼šHello World"}
    ]
  }'
```

#### æ¸…ç©ºä¸Šä¸‹æ–‡

**ç«¯ç‚¹**: `DELETE /llm/context/{session_id}`

```bash
curl -X DELETE "http://localhost:8000/llm/context/user123"
```

#### åˆ é™¤æœ€åä¸€è½®å¯¹è¯

**ç«¯ç‚¹**: `DELETE /llm/context/{session_id}/last`

```bash
curl -X DELETE "http://localhost:8000/llm/context/user123/last"
```

### å¥åº·æ£€æŸ¥

**ç«¯ç‚¹**: `GET /llm/health`

```bash
curl "http://localhost:8000/llm/health"
```

**å“åº”**:
```json
{
  "status": "healthy",
  "service": "llm",
  "timestamp": "2024-01-01T12:00:00Z"
}
```

### æœåŠ¡ä¿¡æ¯

**ç«¯ç‚¹**: `GET /llm/info`

```bash
curl "http://localhost:8000/llm/info"
```

**å“åº”**:
```json
{
  "service": "MyAgent LLM Service",
  "version": "1.0.0",
  "supported_models": [
    "gpt-3.5-turbo",
    "gpt-4",
    "gpt-4-turbo-preview"
  ],
  "features": [
    "chat",
    "context_management",
    "multi_model_support"
  ]
}
```

## ğŸ” OCR API

### æ–‡å­—è¯†åˆ«

**ç«¯ç‚¹**: `POST /ocr/recognize`

#### è¯·æ±‚ä½“

æ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ï¼š

```json
{
  "input": {
    "type": "file_path",
    "data": "/path/to/image.jpg"
  }
}
```

æˆ–è€…ï¼š

```json
{
  "input": {
    "type": "base64",
    "data": "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQ..."
  }
}
```

#### å“åº”

```json
{
  "text": "è¯†åˆ«å‡ºçš„æ–‡å­—å†…å®¹",
  "confidence": 0.95,
  "processing_time": 1.23
}
```

#### cURL ç¤ºä¾‹

```bash
curl -X POST "http://localhost:8000/ocr/recognize" \
  -H "Content-Type: application/json" \
  -d '{
    "input": {
      "type": "file_path",
      "data": "/path/to/image.jpg"
    }
  }'
```

## ğŸ“‹ æ•°æ®æ¨¡å‹

### LLMConfig

```json
{
  "api_key": "string (required)",
  "model": "string (default: gpt-3.5-turbo)",
  "base_url": "string (optional)",
  "temperature": "number (0.0-2.0, default: 0.7)",
  "max_tokens": "integer (optional)",
  "timeout": "integer (default: 30)"
}
```

### ChatRequest

```json
{
  "message": "string (required)",
  "config": "LLMConfig (required)",
  "session_id": "string (optional)",
  "system_prompt": "string (optional)",
  "keep_context": "boolean (default: true)"
}
```

### ChatResponse

```json
{
  "response": "string",
  "session_id": "string",
  "model": "string",
  "usage": {
    "prompt_tokens": "integer",
    "completion_tokens": "integer",
    "total_tokens": "integer"
  }
}
```

### ContextRequest

```json
{
  "messages": [
    {
      "role": "string (user|assistant|system)",
      "content": "string"
    }
  ]
}
```

### ContextResponse

```json
{
  "session_id": "string",
  "messages": "array",
  "message_count": "integer"
}
```

## âŒ é”™è¯¯å¤„ç†

### HTTP çŠ¶æ€ç 

| çŠ¶æ€ç  | æè¿° | ç¤ºä¾‹åœºæ™¯ |
|--------|------|----------|
| 200 | æˆåŠŸ | è¯·æ±‚å¤„ç†æˆåŠŸ |
| 400 | è¯·æ±‚é”™è¯¯ | å‚æ•°æ ¼å¼é”™è¯¯ã€ç¼ºå°‘å¿…éœ€å‚æ•° |
| 401 | è®¤è¯å¤±è´¥ | API å¯†é’¥æ— æ•ˆæˆ–ç¼ºå¤± |
| 404 | èµ„æºä¸å­˜åœ¨ | ä¼šè¯IDä¸å­˜åœ¨ |
| 422 | å‚æ•°éªŒè¯å¤±è´¥ | å‚æ•°ç±»å‹é”™è¯¯ |
| 500 | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ | LLM API è°ƒç”¨å¤±è´¥ |
| 503 | æœåŠ¡ä¸å¯ç”¨ | å¤–éƒ¨æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ |

### é”™è¯¯å“åº”æ ¼å¼

```json
{
  "detail": {
    "error": "error_type",
    "message": "è¯¦ç»†é”™è¯¯ä¿¡æ¯",
    "code": "ERROR_CODE"
  }
}
```

### å¸¸è§é”™è¯¯ç±»å‹

#### é…ç½®é”™è¯¯ (400)

```json
{
  "detail": {
    "error": "configuration_error",
    "message": "api_key is required",
    "code": "MISSING_API_KEY"
  }
}
```

#### è®¤è¯é”™è¯¯ (401)

```json
{
  "detail": {
    "error": "authentication_error",
    "message": "Invalid API key",
    "code": "INVALID_API_KEY"
  }
}
```

#### æ¨¡å‹é”™è¯¯ (400)

```json
{
  "detail": {
    "error": "model_error",
    "message": "Model 'invalid-model' not found",
    "code": "MODEL_NOT_FOUND"
  }
}
```

## ğŸ” è®¤è¯é…ç½®

### API å¯†é’¥ç®¡ç†

API å¯†é’¥é€šè¿‡è¯·æ±‚ä½“ä¸­çš„ `config.api_key` å­—æ®µä¼ é€’ï¼š

```json
{
  "message": "ä½ å¥½",
  "config": {
    "api_key": "your-openai-api-key"
  }
}
```

### æ”¯æŒçš„ LLM æä¾›å•†

#### OpenAI

```json
{
  "api_key": "sk-...",
  "model": "gpt-3.5-turbo",
  "base_url": "https://api.openai.com/v1"
}
```

#### DashScope (é˜¿é‡Œäº‘)

```json
{
  "api_key": "sk-...",
  "model": "qwen-turbo",
  "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"
}
```

#### è‡ªå®šä¹‰ OpenAI å…¼å®¹æœåŠ¡

```json
{
  "api_key": "your-api-key",
  "model": "custom-model",
  "base_url": "https://your-custom-endpoint.com/v1"
}
```

## ğŸ’» å®¢æˆ·ç«¯ç¤ºä¾‹

### JavaScript å®¢æˆ·ç«¯

```javascript
class MyAgentClient {
  constructor(baseUrl = 'http://localhost:8000') {
    this.baseUrl = baseUrl;
  }

  async chat(message, config, options = {}) {
    const response = await fetch(`${this.baseUrl}/llm/chat`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        message,
        config,
        ...options
      })
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(`API Error: ${error.detail.message}`);
    }

    return await response.json();
  }

  async getContext(sessionId) {
    const response = await fetch(`${this.baseUrl}/llm/context/${sessionId}`);
    return await response.json();
  }

  async clearContext(sessionId) {
    await fetch(`${this.baseUrl}/llm/context/${sessionId}`, {
      method: 'DELETE'
    });
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const client = new MyAgentClient();

try {
  const result = await client.chat('ä½ å¥½', {
    api_key: 'your-api-key',
    model: 'gpt-3.5-turbo'
  }, {
    session_id: 'user123'
  });
  
  console.log(result.response);
} catch (error) {
  console.error('èŠå¤©å¤±è´¥:', error.message);
}
```

### Python å®¢æˆ·ç«¯

```python
import requests
import json

class MyAgentClient:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
    
    def chat(self, message: str, config: dict, **kwargs):
        """å‘é€èŠå¤©æ¶ˆæ¯"""
        url = f"{self.base_url}/llm/chat"
        data = {
            "message": message,
            "config": config,
            **kwargs
        }
        
        response = requests.post(url, json=data)
        response.raise_for_status()
        return response.json()
    
    def get_context(self, session_id: str):
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        url = f"{self.base_url}/llm/context/{session_id}"
        response = requests.get(url)
        response.raise_for_status()
        return response.json()
    
    def clear_context(self, session_id: str):
        """æ¸…ç©ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        url = f"{self.base_url}/llm/context/{session_id}"
        response = requests.delete(url)
        response.raise_for_status()

# ä½¿ç”¨ç¤ºä¾‹
client = MyAgentClient()

try:
    result = client.chat(
        message="ä½ å¥½",
        config={
            "api_key": "your-api-key",
            "model": "gpt-3.5-turbo"
        },
        session_id="user123"
    )
    print(result["response"])
except requests.exceptions.RequestException as e:
    print(f"è¯·æ±‚å¤±è´¥: {e}")
```

### curl è„šæœ¬ç¤ºä¾‹

```bash
#!/bin/bash

# é…ç½®
BASE_URL="http://localhost:8000"
API_KEY="your-api-key"
SESSION_ID="test_session"

# èŠå¤©å‡½æ•°
chat() {
    local message="$1"
    curl -s -X POST "${BASE_URL}/llm/chat" \
        -H "Content-Type: application/json" \
        -d "{
            \"message\": \"${message}\",
            \"config\": {
                \"api_key\": \"${API_KEY}\",
                \"model\": \"gpt-3.5-turbo\"
            },
            \"session_id\": \"${SESSION_ID}\"
        }" | jq -r '.response'
}

# è·å–ä¸Šä¸‹æ–‡
get_context() {
    curl -s "${BASE_URL}/llm/context/${SESSION_ID}" | jq '.'
}

# æ¸…ç©ºä¸Šä¸‹æ–‡
clear_context() {
    curl -s -X DELETE "${BASE_URL}/llm/context/${SESSION_ID}"
}

# ä½¿ç”¨ç¤ºä¾‹
echo "å‘é€æ¶ˆæ¯..."
chat "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"

echo -e "\nè·å–ä¸Šä¸‹æ–‡..."
get_context

echo -e "\næ¸…ç©ºä¸Šä¸‹æ–‡..."
clear_context
```

## ğŸ”§ éƒ¨ç½²é…ç½®

### Docker éƒ¨ç½²

```dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY . .

RUN pip install -e .

EXPOSE 8000

CMD ["uvicorn", "src.server.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### ç¯å¢ƒå˜é‡

```bash
# æœåŠ¡é…ç½®
HOST=0.0.0.0
PORT=8000
WORKERS=4

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FORMAT=json

# CORS é…ç½®
CORS_ORIGINS=["http://localhost:3000", "https://yourdomain.com"]
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š

- [å¿«é€Ÿå¼€å§‹æŒ‡å—](quick-start.md)
- [LLM ä½¿ç”¨æŒ‡å—](llm-guide.md)
- [API å‚è€ƒæ–‡æ¡£](api-reference.md)
- [æ¶æ„æ–‡æ¡£](architecture.md)

æˆ–æäº¤ Issue åˆ°é¡¹ç›®ä»“åº“ã€‚